---
layout: post
title: "Impression of Big Data"
category: Big Data
tags: ["big data"]
---

随着目前数据量的发展, 传统的数据处理模式越来越难以满足要求. 下面通过Big Data一书介绍的大数据处理模式来看一下该书中的大数据处理架构如何进行数据处理以及规避传统数据库处理数据时的一些弊端.

下面使用书中给出的示例进行介绍, 假设有一个类似于Google Analytics的功能, 能够统计用户对页面浏览情况, 该应用能够统计互联网上的任意页面的访问量, 另外该应用也能统计访问量前100的URLs

## 传统数据库处理数据方式以及缺点

为了解决上面的问题, 我们建立一个传统数据库的数据模型, 如下表

<table class="table">
  <thead>
    <tr><th>列 名</th><th>类 型</th></tr>
  </thead>
  <tbody>
    <tr><td>id</td><td>integer</td></tr>
    <tr><td>user_id</td><td>integer</td></tr>
    <tr><td>url</td><td>varchar(255)</td></tr>
    <tr><td>pageviews</td><td>bigint</td></tr>
  </tbody>
</table>

当用户点击访问了一个URL, 该用户所对应的url的记录的pageviews值增1, 该设计在低访问量的情况下可以完美的执行.
但是一旦访问量变高, 由于需要频繁从数据库读取记录并更新, 会造成更新数据超时. 如果我们希望快速修正这个问题, 那么在访问数据层之前添加一个缓存队列是一个不错的选择. 当统计应用收到一个页面访问请求, 该事件会直接进入队列, 另外一个线程每次读取100个页面访问请求, 并进行聚合后更新到数据库中, 这种方案可以很好的解决数据库数据更新超时的问题, 而且还有一个好处, 如果后续访问量再次增大, 我们只需要将队列大小调大即可.

但是当该应用变的越来越受欢迎, 数据库最终会再一次成为瓶颈, 通过Google查询"how to scale a write-heavy relational database", 你获得最佳的答案可能是使用多个数据库服务器, 使每一个数据库服务器保存一部分数据, 这就是人们常说的数据水平切分或者数据分片. 该解决方案是将数据库的写负载分摊到多个机器上. 而我们选择对数据的键值做hash, 并对其使用数据分片个数取模. 

加入数据分片后, 所有的应用程序代码需要知道数据分片的存在, 例如上面提到的统计访问量前100的URLs的功能, 我们需要使应用程序对每个分片计算访问量前100的URLs, 并最终汇总到一个服务器上然后进行合并, 得到最终访问量最高的100个URLs. 而且等到这个应用程序越来越欢迎, 为了能够添加更多的数据分片, 我们需要对其重新分片. 而这个过程也会变得越来越痛苦, 因为应用程序里各个功能都需要对分片的加入做相应的协调. 一旦某一个地方忘记更新最新的分片数, 就可能会导致新数据被放到错误的分片上, 而这种错误基本上只能依靠脚本来将所有的数据重新再做一次分片来解决, 这个时间实在是无法估量.

### 随之而来的问题

* 随之分片越来越多, 数据库集群部分机器down掉的几率就大了很多, 这些down掉的机器上的数据就变得不可用, 你可能需要如下方法来解决这个问题
** 更新队列缓存程序, 额外添加一个"Pending"队列, 所有因为机器响应或者其他问题导致的写入超时的数据均添加到这个队列, 然后每隔几分钟, 将该队列的数据写入的数据库中
** 利用数据库副本的功能, 为每一个分片数据库创建副本, 当master down掉后, 虽然此时无法写入数据, 但是仍然可以保证用户能够读取之前的数据.
* 一旦程序有bug, 比如正确的情况下一次访问记录一个点击量, 而程序错误造成一次访问记录了两个点击量, 而这个错误上线后, 我们1天后才发现, 及时有备份, 我们也没办法将数据修正, 因为我们不知道哪些数据遭到了破坏.(这些数据基本上已经没有用了, 因为你只有一周前这个URL的点击量, 而这些URLs后续实际被点击了多少次也无从得知)

### 为什么大数据能够解决上面的问题?

* 首先, 大数据技术相关的数据存储方案都提供了分布式特性, 也就是说数据分片, 数据副本等这些逻辑都内置于数据库中, 我们不再需要对其进行关心, 不会再出现查错分片的情况, 当我们需要对程序作出扩展时, 只需要添加节点, 系统会自动将数据re-banlance到新节点.
* 另外, 由于传统数据库数据量的限制, 我们设计模型时数据往往是可变的, 这样也就导致了我们很难恢复因为bug导致的数据错误或缺失. 而引入大数据的解决方案后, 数据量不再是瓶颈, 我们在设计数据模型时就可以将可变数据模型转化为不可变数据模型, 系统中的数据一旦被保存就不会被修改, 后续的改动都是通过新增数据来达成的, 即使程序问题导致有错误数据, 这部分错误数据也不会影响之前没有问题的数据.


## 理想中的大数据系统需要具备的特点

* 健壮性和容错性
* 低延时的读和写
* 伸缩性
* 通用性
* 可扩展性
* 最小的维护代价
* 容易排错

## Lambda架构如何满足以上特点

<table class="table">
  <thead>
    <tr><th>特 点</th><th>描 述</th></tr>
  </thead>
  <tbody>
    <tr><td>健壮性和容错性</td><td>integer</td></tr>
    <tr><td>低延时的读和写</td><td>integer</td></tr>
    <tr><td>伸缩性</td><td>varchar(255)</td></tr>
    <tr><td>通用性</td><td>bigint</td></tr>
    <tr><td>可扩展性</td><td>bigint</td></tr>
    <tr><td>最小的维护代价</td><td>bigint</td></tr>
    <tr><td>容易排错</td><td>bigint</td></tr>
  </tbody>
</table>

## 数据建模以及存储

## Batch Layer上的计算

## Service Layer

## Speed Layer

## 更深层度的挖掘Lambda架构

## 一些平时工作相关的感想

通过上述介绍的Lambda架构, 从中可以看到Batch Layer中的数据存储全部采用不可变的数据结构, 这样大大的减少了数据处理的复杂度, 因为只有新增和查询操作, 只要数据进入了系统, 该数据不会再进行改变

在我们的工作场景中, 有一个需求需要在某些条件达成下, 自动触发一个或多个命令, 这些需要达成的条件我们可以把它们作为事件, 存储到数据库中, 我们只会定期清理相对较老的同类事件, 这样保证了数据库数据量的规模不会太大. 同时又保证相关逻辑不会太复杂

另外在日常的编程习惯中, 尽可能地使用final字段, 它可以避免引用以及值被意外更改

像书中所总结的query=function(all data), 我们在构造一个方法时尽可能地少依赖上下文, 也就是说类和类, 方法和方法之间模块化, 它们完成功能不需要依赖任何其他的状态, 一个方法对应于一个特定的输入, 它的返回只应该是一个, 这样我们的程序才有可能可控, 风险更低. 工作中常遇到其他组的人遇到各种奇葩问题, 都是由于方法中依赖的一个状态意外被更改而导致的, 而这些错误有时引起的后果又是不可估量的.

## References

Big Data